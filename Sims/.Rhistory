aim2.list <- list(eval=aim2.eval, split=aim2.split, init=aim2.init,
summary=aim2.summary, text=aim2.text)
n <- nrow(dat)
#Identify outcome variable   --- this is redundant with functions statement and should be changed
which.outcome <- which(colnames(dat)==outvar)
colnames(dat)[which.outcome] <- "outvar.aim2"
#Split training set into learning and evaluation sets - now based on 50/50 split
# later look at different alternatives
nlearn <- round(prop.learning*n)
neval <- n-nlearn
samp <- sample(1:n,n,replace=FALSE)
wlearn <- sort(samp[1:nlearn])
weval <- sort(samp[(nlearn+1):n])
learning.dat <- dat[wlearn,]
evaluation.dat <- dat[weval,]
#The lambdas chosen using a grid. Here, get values for variables based on root node
fit.rf.learning <- randomForest(outvar.aim2 ~ .,data = learning.dat) # Fit RF with learning set
predict.rf.evaluation <- predict(fit.rf.learning,newdata=evaluation.dat,
predict.all=TRUE) #  $\widehat{Z}_{1i}$
mean.evaluation <- mean(evaluation.dat$outvar.aim2) # $\mu_{Z_1}$
var.evaluation <- var(evaluation.dat$outvar.aim2) # $\sigma^2_{Z_1}$
zbarhat <- mean(predict.rf.evaluation$aggregate) # $ \bar{\hat{Z_1}}$
# NOTE: this zbarhat means we are doing the
# alternative shrinkage target in equation 9 not the original in 6
var.z1s <-  apply(predict.rf.evaluation$individual,1,var) # $\sigma^2_{\hat{Z_1i}}$
alphas <- 1/var.z1s # $\alpha_i$
alphabar <- mean(alphas) # \bar{\alpha}$
lambda <- var.evaluation/(neval*alphabar*(mean.evaluation-zbarhat)^2) #with-in node
#choice of \lambda
lambdas <- seq(0,mult*lambda,length.out=n.grid)  # list of possible lambdas
n.lambdas <- length(lambdas) #length of list
error.lambdas <- rep(0,length(lambdas))
fits <- vector("list",n.lambdas)
predictions <- vector("list",n.lambdas)
#print("almost there")
# To get the err(\lambda) - uncorrected - currently equation 11
for(j in 1:n.lambdas)
{
#print(lambdas[j])
current.fit <- rpart(outvar.aim2 ~ .,data = evaluation.dat,
parms=list(lambda=lambdas[j],
yhat=predict.rf.evaluation$aggregate,
alpha=alphas),method=aim2.list)
xgroup <- rep(1:10, length = nrow(evaluation.dat))
xfit <- xpred.rpart(current.fit,xgroup)
xerror <- colMeans((xfit - evaluation.dat$outvar.aim2)^2)
min.CP<-current.fit$cptable[which(xerror==min(xerror)),1][1]
current.fit.pruned<-prune(current.fit,cp=min.CP)
predicted.fit <- predict(object=current.fit.pruned,newdata=evaluation.dat)
error.lambdas[j] <- sum((evaluation.dat$outvar.aim2-predicted.fit)^2)
fits[[j]] <- current.fit.pruned
predictions[[j]] <- predicted.fit
}
# To get the optimism for correcting the err(\lambda)
optimism <- corrected.lambda(dat=evaluation.dat,lambdas=lambdas,
list.object=aim2.list,model=fit.rf.learning,
predicted.values=predict.rf.evaluation$aggregate,
alphas=alphas,n.boot=10)
# err(\lambda) corrected
Error.lambdas <- error.lambdas+optimism
#return list of interesting variables.
list(lambdas=lambdas,Error.lambdas=Error.lambdas,error.lambdas=error.lambdas,
optimism=optimism,fits=fits,predictions=predictions,
predicted.fit=predicted.fit,evaluation.dat=evaluation.dat)
}
## @knitr kcorrected.lambda
corrected.lambda <- function(dat,lambdas,list.object,model,predicted.values,alphas,n.boot=10)
{
n1 <- nrow(dat)
p <- ncol(dat)
n.lambdas <- length(lambdas)
cilambda <- matrix(0,n1,n.lambdas)
boot.dat <- boot.residual <- matrix(NA,n1,n.boot)
sigmahat <- sqrt(sum((dat$outvar.aim2-predicted.values)^2)/n1) #SD for \hat{\sigma^2_{Z_1-\bigM}}
for(b in 1:n.boot) boot.dat[,b] <- rnorm(n1,mean=predicted.values,sd=sigmahat)#bootstrap samples
boot.mean <- matrix(apply(boot.dat,1,mean))  # \bar{Z^*_{1i}}
for(i in 1:nrow(boot.dat)) boot.residual[i,] <- boot.dat[i,]-boot.mean[i]
for(b in 1:n.boot)
{
new.dat <- dat
new.dat$outvar.aim2 <- boot.dat[,b]
for(j in 1:n.lambdas)
{
final.fit <- rpart(outvar.aim2 ~ .,data = new.dat,
parms=list(lambda=lambdas[j],
yhat=predicted.values,alpha=alphas),
method=list.object)
xgroup <- rep(1:10, length = nrow(new.dat))
xfit <- xpred.rpart(final.fit,xgroup)
xerror <- colMeans((xfit - new.dat$outvar.aim2)^2)
min.CP<-final.fit$cptable[which(xerror==min(xerror)),1][1]
final.fit.pruned<-prune(final.fit,cp=min.CP)
bigMhat <- predict(object=final.fit.pruned,newdata=new.dat)
cilambda[,j] <- cilambda[,j]+bigMhat*boot.residual[,b]
}
}
cilambda <- cilambda/(n.boot-1)
return(2*apply(cilambda,2,sum))
}
aim2.init <- function(y, offset, parms, wt)
{
if (!is.null(offset)) y[,1] <- y[,1]-offset
list(y=cbind(y,parms$yhat,parms$alpha),parms=parms, numy=3, numresp=1, summary=aim2.summary)
}
aim2.eval <- function(y, wt, parms)
{
n <- length(y)/3
lambda <- parms$lambda
yhat <- y[,2]
alphas <- y[,3]
alphabar <- sum(alphas)/n
y1 <- y[,1]
r <- 1/(1+lambda*alphabar)
zbar <- mean(y1)
zbarhat <- sum(yhat*alphas)/sum(alphas)
chat <- r*zbar+(1-r)*zbarhat
rss <- sum((y1-chat)^2+lambda*alphas*(chat-yhat)^2)
list(label=chat, deviance=rss)
}
aim2.split <- function(y, wt, x, parms, continuous)
{
n <- length(y[,1])
y1 <- y[,1]
yhat <- y[,2]
alpha <- y[,3]
lambda <- parms$lambda
if (continuous)
{
if(is.null(lambda)) compute.lambda #Placeholder until I figure out how to compute lambda
goodness <- direction <- double(n-1) #Allocate 0 vector
y.cumsum <- cumsum(y1)
y.left <- y.cumsum[-n]
y.right <- y.cumsum[n]-y.left
yhat.cumsum <- cumsum(yhat*alpha)
yhat.left <- yhat.cumsum[-n]
yhat.right <- yhat.cumsum[n]-yhat.left
alpha.cumsum <- cumsum(alpha)
alpha.left <- alpha.cumsum[-n]
alpha.right <- alpha.cumsum[n]-alpha.left
for(i in 1:(n-1))
{
zbar.left <- y.left[i]/i
zbar.right <- y.right[i]/(n-i)
zbarhat.left <- yhat.left[i]/alpha.left[i]
zbarhat.right <- yhat.right[i]/alpha.right[i]
alphabar.left <- alpha.left[i]/i
alphabar.right <- alpha.right[i]/(n-i)
r.left <- 1/(1+lambda*alphabar.left)
r.right <- 1/(1+lambda*alphabar.right)
chat.left <- r.left*zbar.left+(1-r.left)*zbarhat.left
chat.right <- r.right*zbar.right+(1-r.right)*zbarhat.right
#            goodness[i] <- sum((y1-mean(y1))^2)
#                 - (sum((y1[1:i]-chat.left)^2 +
#                    lambda*alpha[1:i]*(yhat[1:i]-chat.left)^2) +
#                   sum((y1[(i+1):n]-chat.right)^2 +
#                  lambda*alpha[(i+1):n]*(yhat[(i+1):n]-chat.right)^2))
#           Do we need adjustment for missing values like in  vignette example?
direction[i] <- sign(zbar.left-zbar.right)
goodness.left <- sum((y1[1:i]-chat.left)^2 + lambda*alpha[1:i]*(yhat[1:i]-chat.left)^2)
goodness.right <- sum((y1[(i+1):n]-chat.right)^2 +
lambda*alpha[(i+1):n]*(yhat[(i+1):n]-chat.right)^2)
tss <- sum((y1-mean(y1))^2)
goodness[i] <- tss-goodness.left-goodness.right
}
} # this means we can only have x continuous - no categorical
#    goodness <- 1/goodness
return(list(goodness=goodness, direction=direction))
}
aim2.summary <- function(yval, dev, wt, ylevel, digits )
{
paste(" mean=", format(signif(yval, digits)), ", MSE=" , format(signif(dev/wt, digits)), sep= '')
}
aim2.text <- function(yval, dev, wt, ylevel, digits, n, use.n )
{
if(use.n) paste(formatg(yval,digits)," nn=", n,sep="")
else paste(formatg(yval,digits))
}
n <- nrow(dat)
which.outcome <- which(colnames(dat)==outvar)
colnames(dat)[which.outcome] <- "outvar.aim2"
nlearn <- round(prop.learning*n)
neval <- n-nlearn
samp <- sample(1:n,n,replace=FALSE)
wlearn <- sort(samp[1:nlearn])
weval <- sort(samp[(nlearn+1):n])
learning.dat <- dat[wlearn,]
evaluation.dat <- dat[weval,]
nlearn <- round(prop.learning*n)
prop.learning=0.5
nlearn <- round(prop.learning*n)
neval <- n-nlearn
samp <- sample(1:n,n,replace=FALSE)
wlearn <- sort(samp[1:nlearn])
weval <- sort(samp[(nlearn+1):n])
learning.dat <- dat[wlearn,]
evaluation.dat <- dat[weval,]
fit.rf.learning <- randomForest(outvar.aim2 ~ .,data = learning.dat) # Fit RF with learning set
predict.rf.evaluation <- predict(fit.rf.learning,newdata=evaluation.dat,predict.all=TRUE) #  $\widehat{Z}_{1i}$
mean.evaluation <- mean(evaluation.dat$outvar.aim2) # $\mu_{Z_1}$
evaluation.dat$outvar.aim2
evaluation.dat$outvar.aim2
evaluation.dat[1,]
evaluation.dat$outvar.aim2
mode(evaluation.dat)
class(evaluation.dat)
source('~/Respository/Aim2/IntegratingCodeAndText_postAMM.R')
model<-cmdArg(model="sim1")
tag <-cmdArg(tag="notag")
n.training <- cmdArg(n.training=250L)
n.test <- cmdArg(n.test=1000L)
n.simulations <- cmdArg(n.simulations=1000L)
leafytrees <- cmdArg(leafytrees=500L)
name <- paste("data/",model,"_",tag,"_",sep="")
rf <- paste("CompositeDC/",model,"_",tag,"_",sep="")
idx<-1
training.data.all<-data.frame(cbind(training.data,training.y))
dimnames(training.data.all)[[2]]<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9","training.y")
system.time(Model<-composite.rpart(dat=training.data.all,n.grid=50,mult=4,outvar="training.y"))
Model
temp <-
plot(Model$lambdas,Model$error.lambdas,xlab="lambda",ylab="Optimism corrected error",
main="DC Code: Optimism corrected error vs. lambda for housing data")
lambda.num<-which(Model$error.lambdas==min(Model$error.lambdas))
MinErrorLambda<-Model$lambdas[lambda.num]
dimnames(test.data)[[2]]<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9")
PredictedValuesCurrent<-predict(object=Model$fits[[lambda.num]],newdata=test.data)
test.data <- data.frame(scan(paste(name,"test_data_",idx,".txt",sep="")),nrow=n.test,byrow=TRUE)
test.data <- matrix(scan(paste(name,"test_data_",idx,".txt",sep="")),nrow=n.test,byrow=TRUE)
dim(test.data)
test.data <- data.frame(scan(paste(name,"test_data_",idx,".txt",sep="")),nrow=n.test,byrow=TRUE)
dimnames(test.data)[[2]]<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9")
colnames(test.data)<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9")
dim(test.data)
test.data <- data.frame(scan(paste(name,"test_data_",idx,".txt",sep="")),nrow=n.test,byrow=TRUE)
dim(test.data)
test.data<-data.frame(test.data)
dimnames(test.data)[[2]]<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9")
dim(test.data)
test.data[1,]
test.data <- matrix(scan(paste(name,"test_data_",idx,".txt",sep="")),nrow=n.test,byrow=TRUE)
dim(test.data)
test.data[1,]
dimnames(test.data)[[2]]<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9")
dim(test.data)
test.data[1,]
test.data<-as.data.frame(test.data)
PredictedValuesCurrent<-predict(object=Model$fits[[lambda.num]],newdata=test.data)
PredictedValuesCurrent
length(test.truth)
(sum(( PredictedValuesCurrent - as.matrix(test.truth))^2))/n.test
ErrorToTruthCurrent<-(sum(( PredictedValuesCurrent - as.matrix(test.truth))^2))/n.test
write(PredictedValuesCurrent,paste(rf,"rf_PredictedValuesCurrent_",idx,".txt",sep=""),ncol=1)
write(VIMPCurrent,paste(rf,"rf_VIMPCurrent_",idx,".txt",sep=""),ncol=1)
write(ErrorToTruthCurrent,paste(rf,"rf_ErrorToTruthCurrent_",idx,".txt",sep=""),ncol=1)
system.time(Model<-composite.rpart(dat=training.data.all,n.grid=100,mult=4,outvar="training.y"))
lambda.num<-which(Model$error.lambdas==min(Model$error.lambdas))
MinErrorLambda<-Model$lambdas[lambda.num]
PredictedValuesCurrent<-predict(object=Model$fits[[lambda.num]],newdata=test.data)
ErrorToTruthCurrent<-(sum(( PredictedValuesCurrent - as.matrix(test.truth))^2))/n.test
ErrorToTruthCurrent
lambda.num
MinErrorLambda
plot(Model$lambdas,Model$error.lambdas,xlab="lambda",ylab="Optimism corrected error",
+        main="DC Code: Optimism corrected error vs. lambda for housing data")
plot(Model$lambdas,Model$error.lambdas)
plot(Model$lambdas,Model$error.lambdas)
system.time(Model<-composite.rpart.Grid(dat = gen.data, n.grid = 20, mult = 1,
uplim = 20, outvar = "mdev", prop.learning = 0.5))
system.time(Model<-composite.rpart.Grid(dat = training.data.all, n.grid = 20, mult = 1,
uplim = 20, outvar = "mdev", prop.learning = 0.5))
system.time(Model<-composite.rpart.Grid(dat = training.data.all, n.grid = 20, mult = 1,
uplim = 20, outvar = "training.y", prop.learning = 0.5))
lambda.num<-which(Model$CVError.lambdas==min(Model$CVError.lambdas))
MinErrorLambda<-Model$CVError.lambdas[lambda.num]
PredictedValuesCurrent<-predict(object=Model$fits[[lambda.num]],newdata=test.data)
ErrorToTruthCurrent<-(sum(( PredictedValuesCurrent - as.matrix(test.truth))^2))/n.test
ErrorToTruthCurrent
source('~/Respository/Aim2/IntegratingCodeAndText_postAMM.R')
source('~/Respository/Aim2/IntegratingCodeAndText_postAMM.R')
source('~/Respository/Aim2/IntegratingCodeAndText_postAMM.R')
system.time(Model<-composite.rpart.Grid(dat = training.data.all, n.grid = 100, mult = 1,
uplim = 40, outvar = "training.y", prop.learning = 0.5))
MinErrorLambda<-Model$CVError.lambdas[lambda.num]
PredictedValuesCurrent<-predict(object=Model$fits[[lambda.num]],newdata=test.data)
ErrorToTruthCurrent<-(sum(( PredictedValuesCurrent - as.matrix(test.truth))^2))/n.test
ErrorToTruthCurrent
lambda.num<-which(Model$CVError.lambdas==min(Model$CVError.lambdas))
MinErrorLambda<-Model$CVError.lambdas[lambda.num]
PredictedValuesCurrent<-predict(object=Model$fits[[lambda.num]],newdata=test.data)
ErrorToTruthCurrent<-(sum(( PredictedValuesCurrent - as.matrix(test.truth))^2))/n.test
write(MinErrorLambda,paste(CompositeRob,"CompositeRob_MinErrorLambda_",idx,".txt",sep=""),ncol=1)
write(PredictedValuesCurrent,paste(CompositeRob,"CompositeRob_PredictedValuesCurrent_",idx,".txt",sep=""),ncol=1)
write(ErrorToTruthCurrent,paste(CompositeRob,"CompositeRob_ErrorToTruthCurrent_",idx,".txt",sep=""),ncol=1)
lambda.num<-which(Model$CVError.lambdas==min(Model$CVError.lambdas))
MinErrorLambda<-Model$CVError.lambdas[lambda.num]
PredictedValuesCurrent<-predict(object=Model$fits[[lambda.num]],newdata=test.data)
ErrorToTruthCurrent<-(sum(( PredictedValuesCurrent - as.matrix(test.truth))^2))/n.test
write(MinErrorLambda,paste(CompositeRob,"CompositeRob_MinErrorLambda_",idx,".txt",sep=""),ncol=1)
write(PredictedValuesCurrent,paste(CompositeRob,"CompositeRob_PredictedValuesCurrent_",idx,".txt",sep=""),ncol=1)
write(ErrorToTruthCurrent,paste(CompositeRob,"CompositeRob_ErrorToTruthCurrent_",idx,".txt",sep=""),ncol=1)
CompositeRob <- paste("CompositeRob/",model,"_",tag,"_",sep="")
write(MinErrorLambda,paste(CompositeRob,"CompositeRob_MinErrorLambda_",idx,".txt",sep=""),ncol=1)
write(PredictedValuesCurrent,paste(CompositeRob,"CompositeRob_PredictedValuesCurrent_",idx,".txt",sep=""),ncol=1)
write(ErrorToTruthCurrent,paste(CompositeRob,"CompositeRob_ErrorToTruthCurrent_",idx,".txt",sep=""),ncol=1)
system("/Users/annettemolinaro/Respository/Reproduce_jcgs_manuscript/friedman1/compile.sh")
cat CompositeDC/sim1_notag_CompositeDC_*ErrorToTruth* > friedman1_CompositeDC_ErrorToTruth.txt
read.file("friedman1_CompositeThirds_ErrorToTruth.txt")
read.file("friedman1_CompositeThirds_ErrorToTruth.txt")
read("friedman1_CompositeThirds_ErrorToTruth.txt")
read.table("friedman1_CompositeThirds_ErrorToTruth.txt")
compdc.error<-read.table("friedman1_CompositeDC_ErrorToTruth.txt")
compthirds.error<-read.table("friedman1_CompositeThirds_ErrorToTruth.txt")
dim(compdc.error)
apply(compdc.error,2,mean)
apply(compdc.error,2,st.dev)
apply(compdc.error,2,std)
apply(compdc.error,2,var)
sqrt(apply(compdc.error,2,var))
apply(compdc.error,2,mean)
sqrt(apply(compdc.error,2,var))
apply(compthirds.error,2,mean)
sqrt(apply(compthirds.error,2,var))
compRob.error<-read.table("friedman1_CompositeRob_ErrorToTruth.txt")
apply(compRob.error,2,mean)
sqrt(apply(compRob.error,2,var))
compdc.error<-read.table("friedman1_CompositeDC_ErrorToTruth.txt")
compthirds.error<-read.table("friedman1_CompositeThirds_ErrorToTruth.txt")
compRob.error<-read.table("friedman1_CompositeRob_ErrorToTruth.txt")
apply(compdc.error,2,mean)
sqrt(apply(compdc.error,2,var))
apply(compthirds.error,2,mean)
sqrt(apply(compthirds.error,2,var))
apply(compRob.error,2,mean)
sqrt(apply(compRob.error,2,var))
apply(compdc.error,2,mean)
sqrt(apply(compdc.error,2,var))
apply(compthirds.error,2,mean)
sqrt(apply(compthirds.error,2,var))
apply(compRob.error,2,mean)
sqrt(apply(compRob.error,2,var))
pwd()
pwd
wd()
getwd
getwd()
Model$CVError.lambdas
attributes(Model)
source("/Users/annettemolinaro/Respository/Aim2/IntegratingCodeAndText_postAMM.R")
model<-cmdArg(model="sim1")
tag <-cmdArg(tag="notag")
n.training <- cmdArg(n.training=250L)
n.test <- cmdArg(n.test=1000L)
n.simulations <- cmdArg(n.simulations=1000L)
name <- paste("data/",model,"_",tag,"_",sep="")
CompositeRob <- paste("CompositeRob/",model,"_",tag,"_",sep="")
idx<-1
set.seed(idx)
training.data <- matrix(scan(paste(name,"training_data_",idx,".txt",sep="")),nrow=n.training,byrow=TRUE)
test.data <- matrix(scan(paste(name,"test_data_",idx,".txt",sep="")),nrow=n.test,byrow=TRUE)
training.y <- scan(paste(name,"training_y_",idx,".txt",sep=""))
test.y <- scan(paste(name,"test_y_",idx,".txt",sep=""))
training.truth <- scan(paste(name,"training_truth_",idx,".txt",sep=""))
test.truth <- scan(paste(name,"test_truth_",idx,".txt",sep=""))
training.data.all<-data.frame(cbind(training.data,training.y))
dimnames(training.data.all)[[2]]<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9","training.y")
dimnames(test.data)[[2]]<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9")
test.data<-as.data.frame(test.data)
system.time(Model<-composite.rpart.Grid(dat = training.data.all, n.grid =20, mult = 1,
uplim = 20, outvar = "training.y", prop.learning = 0.5))
attributes(Model)
lambda.num<-which(Model$CVError.lambdas==min(Model$CVError.lambdas))
MinErrorLambda<-Model$CVError.lambdas[lambda.num]
PredictedValuesCurrent<-predict(object=Model$fits[[lambda.num]],newdata=test.data)
ErrorToTruthCurrent<-(sum(( PredictedValuesCurrent - as.matrix(test.truth))^2))/n.test
PredictedValuesCurrent
ErrorToTruthCurrent<-(sum(( PredictedValuesCurrent - as.matrix(test.truth))^2))/n.test
write(MinErrorLambda,paste(CompositeRob,"CompositeRob_MinErrorLambda_",idx,".txt",sep=""),ncol=1)
ErrorToTruthCurrent
lambda.num<-which(Model$Error.lambdas==min(Model$Error.lambdas))
MinErrorLambda<-Model$Error.lambdas[lambda.num]
PredictedValuesCurrent<-predict(object=Model$fits[[lambda.num]],newdata=test.data)
ErrorToTruthCurrent<-(sum(( PredictedValuesCurrent - as.matrix(test.truth))^2))/n.test
ErrorToTruthCurrent
lambda.num<-which(Model$errorU.lambdas==min(Model$errorU.lambdas))
MinErrorLambda<-Model$errorU.lambdas[lambda.num]
PredictedValuesCurrent<-predict(object=Model$fits[[lambda.num]],newdata=test.data)
ErrorToTruthCurrent<-(sum(( PredictedValuesCurrent - as.matrix(test.truth))^2))/n.test
ErrorToTruthCurrent
lambda.num<-which(Model$error.lambdas==min(Model$error.lambdas))
MinErrorLambda<-Model$error.lambdas[lambda.num]
PredictedValuesCurrent<-predict(object=Model$fits[[lambda.num]],newdata=test.data)
ErrorToTruthCurrent<-(sum(( PredictedValuesCurrent - as.matrix(test.truth))^2))/n.test
ErrorToTruthCurrent
source("/Users/annettemolinaro/Respository/Aim2/IntegratingCodeAndText_postAMM.R")
model<-cmdArg(model="sim1")
tag <-cmdArg(tag="notag")
n.training <- cmdArg(n.training=250L)
n.test <- cmdArg(n.test=1000L)
n.simulations <- cmdArg(n.simulations=500L)
name <- paste("data/",model,"_",tag,"_",sep="")
CompositeThirds <- paste("CompositeThirds/",model,"_",tag,"_",sep="")
set.seed(idx)
training.data <- matrix(scan(paste(name,"training_data_",idx,".txt",sep="")),nrow=n.training,byrow=TRUE)
test.data <- matrix(scan(paste(name,"test_data_",idx,".txt",sep="")),nrow=n.test,byrow=TRUE)
training.y <- scan(paste(name,"training_y_",idx,".txt",sep=""))
test.y <- scan(paste(name,"test_y_",idx,".txt",sep=""))
training.truth <- scan(paste(name,"training_truth_",idx,".txt",sep=""))
test.truth <- scan(paste(name,"test_truth_",idx,".txt",sep=""))
training.data.all<-data.frame(cbind(training.data,training.y))
dimnames(training.data.all)[[2]]<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9","training.y")
dimnames(test.data)[[2]]<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9")
test.data<-as.data.frame(test.data)
system.time(Model<-composite.rpart.thirds(dat=training.data.all,n.grid=100,mult=4,outvar="training.y"))
lambda.num<-which(Model$error.lambdas==min(Model$error.lambdas))
MinErrorLambda<-Model$lambdas[lambda.num]
PredictedValuesCurrent<-predict(object=Model$fits[[lambda.num]],newdata=test.data)
ErrorToTruthCurrent<-(sum(( PredictedValuesCurrent - as.matrix(test.truth))^2))/n.test
ErrorToTruthCurrent
system.time(Model<-composite.rpart.thirds.Newer(dat=training.data.all,n.grid=100,mult=4,outvar="training.y"))
source("/Users/annettemolinaro/Respository/Aim2/IntegratingCodeAndText_postAMM.R")
system.time(Model<-composite.rpart.thirds.Newer(dat=training.data.all,n.grid=100,mult=4,outvar="training.y"))
system.time(Model<-composite.rpart.thirds.newer(dat=training.data.all,n.grid=100,mult=4,outvar="training.y"))
composite.rpart.thirds.newer
set.seed(idx)
training.data <- matrix(scan(paste(name,"training_data_",idx,".txt",sep="")),nrow=n.training,byrow=TRUE)
test.data <- matrix(scan(paste(name,"test_data_",idx,".txt",sep="")),nrow=n.test,byrow=TRUE)
training.y <- scan(paste(name,"training_y_",idx,".txt",sep=""))
test.y <- scan(paste(name,"test_y_",idx,".txt",sep=""))
training.truth <- scan(paste(name,"training_truth_",idx,".txt",sep=""))
test.truth <- scan(paste(name,"test_truth_",idx,".txt",sep=""))
training.data.all<-data.frame(cbind(training.data,training.y))
dimnames(training.data.all)[[2]]<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9","training.y")
dimnames(test.data)[[2]]<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9")
test.data<-as.data.frame(test.data)
system.time(Model<-composite.rpart.thirds.newer(dat=training.data.all,n.grid=100,mult=4,outvar="training.y"))
composite.rpart.thirds.newer
source('~/Respository/Aim2/IntegratingCodeAndText_postAMM.R')
source("/Users/annettemolinaro/Respository/Aim2/IntegratingCodeAndText_postAMM.R")
system.time(Model<-composite.rpart.thirds.newer(dat=training.data.all,n.grid=100,mult=4,outvar="training.y"))
lambda.num<-which(Model$error.lambdas==min(Model$error.lambdas))
MinErrorLambda<-Model$lambdas[lambda.num]
PredictedValuesCurrent<-predict(object=Model$fits[[lambda.num]],newdata=test.data)
ErrorToTruthCurrent<-(sum(( PredictedValuesCurrent - as.matrix(test.truth))^2))/n.test
ErrorToTruthCurrent
Model$error.lambdas
system.time(Model<-composite.rpart.thirds(dat=training.data.all,n.grid=100,mult=4,outvar="training.y"))
Model$error.lambdas
lambda.num<-which(Model$error.lambdas==min(Model$error.lambdas))
MinErrorLambda<-Model$lambdas[lambda.num]
PredictedValuesCurrent<-predict(object=Model$fits[[lambda.num]],newdata=test.data)
ErrorToTruthCurrent<-(sum(( PredictedValuesCurrent - as.matrix(test.truth))^2))/n.test
write(MinErrorLambda,paste(CompositeThirdsNewer,"CompositeThirdsNewer_MinErrorLambda_",idx,".txt",sep=""),ncol=1)
write(PredictedValuesCurrent,paste(CompositeThirdsNewer,"CompositeThirdsNewer_PredictedValuesCurrent_",idx,".txt",sep=""),ncol=1)
write(ErrorToTruthCurrent,paste(CompositeThirdsNewer,"CompositeThirdsNewer_ErrorToTruthCurrent_",idx,".txt",sep=""),ncol=1)
CompositeThirds <- paste("CompositeThirds/",model,"_",tag,"_",sep="")
set.seed(idx)
training.data <- matrix(scan(paste(name,"training_data_",idx,".txt",sep="")),nrow=n.training,byrow=TRUE)
test.data <- matrix(scan(paste(name,"test_data_",idx,".txt",sep="")),nrow=n.test,byrow=TRUE)
training.y <- scan(paste(name,"training_y_",idx,".txt",sep=""))
test.y <- scan(paste(name,"test_y_",idx,".txt",sep=""))
training.truth <- scan(paste(name,"training_truth_",idx,".txt",sep=""))
test.truth <- scan(paste(name,"test_truth_",idx,".txt",sep=""))
training.data.all<-data.frame(cbind(training.data,training.y))
dimnames(training.data.all)[[2]]<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9","training.y")
dimnames(test.data)[[2]]<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9")
test.data<-as.data.frame(test.data)
system.time(Model<-composite.rpart.thirds(dat=training.data.all,n.grid=100,mult=4,outvar="training.y"))
lambda.num<-which(Model$error.lambdas==min(Model$error.lambdas))
MinErrorLambda<-Model$lambdas[lambda.num]
PredictedValuesCurrent<-predict(object=Model$fits[[lambda.num]],newdata=test.data)
ErrorToTruthCurrent<-(sum(( PredictedValuesCurrent - as.matrix(test.truth))^2))/n.test
write(MinErrorLambda,paste(CompositeThirds,"CompositeThirds_MinErrorLambda_",idx,".txt",sep=""),ncol=1)
write(PredictedValuesCurrent,paste(CompositeThirds,"CompositeThirds_PredictedValuesCurrent_",idx,".txt",sep=""),ncol=1)
write(ErrorToTruthCurrent,paste(CompositeThirds,"CompositeThirds_ErrorToTruthCurrent_",idx,".txt",sep=""),ncol=1)
ErrorToTruthCurrent
lambda.num
which(Model$error.lambdas==min(Model$error.lambdas))
Model$error.lambdas
min(Model$error.lambdas)
compRob.CVerror<-read.table("friedman1_CompositeRob_ErrorToTruth.txt")
compRob.CVerror<-read.table("friedman1_CompositeRob_ErrorToTruth.txt")
setwd("/Users/annettemolinaro/Respository/Aim2/Sims")
setwd("/Users/annettemolinaro/Respository/Aim2/Sims")
compdc.error<-read.table("friedman1_CompositeDC_ErrorToTruth.txt")
source("/Users/annettemolinaro/Respository/Aim2/IntegratingCodeAndText_postAMM.R")
model<-cmdArg(model="sim1")
tag <-cmdArg(tag="notag")
n.training <- cmdArg(n.training=250L)
n.test <- cmdArg(n.test=1000L)
n.simulations <- cmdArg(n.simulations=500L)
name <- paste("data/",model,"_",tag,"_",sep="")
CompositeThirds <- paste("CompositeThirds/",model,"_",tag,"_",sep="")
idx
set.seed(idx)
training.data <- matrix(scan(paste(name,"training_data_",idx,".txt",sep="")),nrow=n.training,byrow=TRUE)
test.data <- matrix(scan(paste(name,"test_data_",idx,".txt",sep="")),nrow=n.test,byrow=TRUE)
training.y <- scan(paste(name,"training_y_",idx,".txt",sep=""))
test.y <- scan(paste(name,"test_y_",idx,".txt",sep=""))
training.truth <- scan(paste(name,"training_truth_",idx,".txt",sep=""))
test.truth <- scan(paste(name,"test_truth_",idx,".txt",sep=""))
training.data.all<-data.frame(cbind(training.data,training.y))
dimnames(training.data.all)[[2]]<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9","training.y")
dimnames(test.data)[[2]]<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9")
test.data<-as.data.frame(test.data)
system.time(Model<-composite.rpart.thirds(dat=training.data.all,n.grid=100,mult=4,outvar="training.y"))
PredictedValuesCurrent<-predict(object=Model$current.fit.pruned,newdata=test.data)
ErrorToTruthCurrent<-(sum(( PredictedValuesCurrent - as.matrix(test.truth))^2))/n.test
ErrorToTruthCurrent
PredictedValuesCurrent
compthirds.error<-read.table("friedman1_CompositeThirds_ErrorToTruth.txt")
setwd("/Users/annettemolinaro/Respository/Aim2/Sims")
read_chunk("/Users/annettemolinaro/Respository/Aim2/IntegratingCodeAndText_postAMM.R")
